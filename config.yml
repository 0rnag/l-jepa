train_split: 0.9
eval_split: 0.1

n_embed: 384
num_heads: 6
block_size: 512
num_layers: 6
encoder_dim: 384
dropout: 0.2

batch_size: 64
num_epochs: 5
lr: 0.0003
min_masked_tokens: 0.1
max_masked_tokens: 0.3
ema_decay: 0.996
ema_final: 1.0

predictor_num_layers: 2
predictor_dim_multiplier: 4

finetune_lr: 0.00008
finetune_batch_size: 64
finetune_num_epochs: 5
finetune_split_ratio: 0.5
finetune_dropout: 0.2